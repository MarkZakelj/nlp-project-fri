{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertPreTrainedModel, AdamW, AutoTokenizer, BertConfig, BertModel\n",
    "from rbert_model import RBERT\n",
    "import os\n",
    "import numpy as np\n",
    "from rbert_data_loader import load_and_cache_examples\n",
    "from train_relation_extraction import RelationExtractorTrainer, get_tokenizer, model_id_to_path\n",
    "from rbert_data_loader import TermFrameProcessor, convert_examples_to_features\n",
    "import torch\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conf = {'experiment': 'EN_reg_nonhier+def',\n",
    "        'model_id': 'allenai/scibert_scivocab_cased',\n",
    "        'max_length': 128,\n",
    "        'batch_size': 4,\n",
    "        'epochs': 5}\n",
    "conf['model_dir'] = os.path.join('data', 'experiments', conf['experiment'], model_id_to_path(conf['model_id']))\n",
    "conf['eval_dir'] = conf['model_dir']\n",
    "conf['data_dir'] = os.path.join('data', 'experiments', conf['experiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(conf['model_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "processor = TermFrameProcessor(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RBERT(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31116, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls_fc_layer): FCLayer(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (entity_fc_layer): FCLayer(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (label_classifier): FCLayer(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear): Linear(in_features=2304, out_features=7, bias=True)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = torch.load(os.path.join(conf['model_dir'], \"training_args.bin\"))\n",
    "model = RBERT.from_pretrained(os.path.join(conf['model_dir'], 'model.pt'), args=args)\n",
    "model.to(device);\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_line(line) :\n",
    "    examples = processor._create_examples(line, 'train')\n",
    "    features = convert_examples_to_features(\n",
    "        examples, conf['max_length'], tokenizer, add_sep_token=False\n",
    "    )\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long, device=device)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long, device=device)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long, device=device)\n",
    "    all_e1_mask = torch.tensor([f.e1_mask for f in features], dtype=torch.long, device=device)  # add e1 mask\n",
    "    all_e2_mask = torch.tensor([f.e2_mask for f in features], dtype=torch.long, device=device)  # add e2 mask\n",
    "\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long, device=device)\n",
    "    \n",
    "    # for i in range(len(all_input_ids))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(all_input_ids, all_attention_mask, all_token_type_ids, None, all_e1_mask, all_e2_mask)\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        probs = softmax(logits, axis=1)\n",
    "    detection = 0\n",
    "    max_val = np.max(logits[0])\n",
    "    if max_val > 7:\n",
    "        detection = np.argmax(logits[0])\n",
    "    \n",
    "    return detection, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.45941   -2.0900204 -1.6167957 -1.8023508 -1.9084367 -1.7309326\n",
      "  -1.7495626]]\n",
      "[[10.535376  -1.9328756 -1.6672069 -1.9021527 -1.7403682 -1.823944\n",
      "  -1.8182349]]\n",
      "[[10.551659  -2.0295384 -1.7098657 -1.9516482 -1.6418275 -1.88708\n",
      "  -1.5329087]]\n",
      "[[10.564585  -2.0932128 -1.9275554 -1.6084161 -1.656087  -2.032623\n",
      "  -1.5767817]]\n",
      "[[10.503424  -1.9429697 -1.8709061 -1.9238069 -1.4655601 -2.079242\n",
      "  -1.521052 ]]\n",
      "[[-0.26385963 -1.7008317  -2.9521842  -0.9481971  -0.40331048 -2.4300153\n",
      "   7.942303  ]]\n",
      "Found 6\n",
      "[[10.493633  -2.1466563 -2.0746891 -1.593467  -1.5134028 -2.2493997\n",
      "  -1.2057354]]\n",
      "0\n",
      "[[ 5.4637904 -3.012116  -3.4803064  1.7157595 -1.4539253 -3.0508163\n",
      "   3.5833077]]\n",
      "[[-0.15626672 -2.3901618  -1.9791044   9.245464   -2.7628362  -2.0311084\n",
      "  -1.2988751 ]]\n",
      "Found 3\n",
      "[[-0.16115616 -2.3991754  -1.7899622   9.399419   -2.651478   -2.1623378\n",
      "  -1.5740547 ]]\n",
      "3\n",
      "[[ 9.049711  -2.2166717 -2.334558   1.3186641 -2.0022838 -2.6791286\n",
      "  -1.9191375]]\n",
      "0\n",
      "[[ 0.9141397 -1.7678968 -1.9254615 -0.6315382  7.201113  -2.6668408\n",
      "  -1.6346495]]\n",
      "Found 4\n",
      "[[10.5378275 -2.134291  -1.859326  -1.843481  -1.3959246 -1.9549361\n",
      "  -1.7464656]]\n",
      "0\n",
      "[[10.446022  -2.2486286 -1.767402  -1.8092446 -1.6366019 -1.6856573\n",
      "  -1.8399744]]\n",
      "[[10.477715  -1.8531758 -1.8950379 -2.0397775 -1.5503536 -1.7506404\n",
      "  -1.7812853]]\n",
      "[[10.188406  -1.8241274 -2.0186565 -1.9875196 -1.9608265 -1.1728666\n",
      "  -2.0085611]]\n",
      "[[10.438436  -1.7786177 -1.6681187 -2.0788212 -1.587792  -1.7865139\n",
      "  -1.9255702]]\n",
      "[[-1.0550001 -0.2587677  3.5559    -2.3982012 -2.9555576  3.659166\n",
      "  -2.6967406]]\n",
      "[[10.184593  -1.6995616 -1.6627336 -2.1817205 -1.4308387 -1.6065054\n",
      "  -1.9216669]]\n",
      "[[ 8.8905735  -1.4860805  -1.3529506  -2.3843055  -1.6217436  -0.34253323\n",
      "  -2.4692554 ]]\n",
      "[[-1.6244313  1.1583078  3.0128763 -3.3147519 -1.4883914  3.2474785\n",
      "  -2.940087 ]]\n",
      "[[10.396906  -1.77304   -1.7373561 -2.0459435 -1.6236397 -1.6854551\n",
      "  -1.880792 ]]\n",
      "[[ 3.6808264  -0.20748295  1.3961961  -2.9303887  -1.5288774   0.25542322\n",
      "  -2.2634547 ]]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .\"\n",
    "i1 = sentence.find('<e1>')\n",
    "i2 = sentence.find('</e1>')\n",
    "window_size_start = 2\n",
    "window_size = window_size_start\n",
    "words_before = sentence[:i1].strip().split(' ')\n",
    "words_after = sentence[i2:].strip().split(' ')\n",
    "lines = []\n",
    "preds = []\n",
    "idx1 = 0\n",
    "while idx1 < (len(words_before) - window_size + 1):\n",
    "    idx2 = idx1 + window_size\n",
    "    e2_before = words_before[:idx1] + ['<e2>'] + words_before[idx1:idx2] + ['</e2>'] + words_before[idx2:]\n",
    "    line = [['Other', ' '.join(e2_before) + ' ' + sentence[i1:]]]\n",
    "    prediction, confidence = predict_line(line)\n",
    "    \n",
    "    if prediction != 0 :\n",
    "        max_confidence = confidence\n",
    "        nu_prediction = prediction\n",
    "        nu_confidence = confidence\n",
    "        e2_before_nu = e2_before\n",
    "        \n",
    "        window_size += 1\n",
    "        while prediction == nu_prediction and idx2 < len(words_before) and max_confidence >= nu_confidence - 1 :\n",
    "            e2_before = e2_before_nu\n",
    "            \n",
    "            idx2 = idx1 + window_size\n",
    "            e2_before_nu = words_before[:idx1] + ['<e2>'] + words_before[idx1:idx2] + ['</e2>'] + words_before[idx2:]\n",
    "            nu_line = [['Other', ' '.join(e2_before_nu) + ' ' + sentence[i1:]]]\n",
    "            nu_prediction, nu_confidence = predict_line(nu_line)\n",
    "            if nu_confidence > max_confidence :\n",
    "                max_confidence = nu_confidence\n",
    "            \n",
    "            window_size += 1\n",
    "            \n",
    "        preds.append([str(prediction), ' '.join(e2_before) + ' ' + sentence[i1:]])\n",
    "        idx1 += window_size - 1\n",
    "        window_size = window_size_start\n",
    "    \n",
    "    idx1 += 1\n",
    "\n",
    "idx1 = 0\n",
    "while idx1 < len(words_after):\n",
    "    idx2 = idx1 + window_size\n",
    "    e2_after = words_after[:idx1] + ['<e2>'] + words_after[idx1:idx2] + ['</e2>'] + words_after[idx2:]\n",
    "    line = [['Other', sentence[:i2] + ' ' + ' '.join(e2_after)]]\n",
    "    prediction, confidence = predict_line(line)\n",
    "    \n",
    "    if prediction != 0 :\n",
    "        max_confidence = confidence\n",
    "        nu_prediction = prediction\n",
    "        nu_confidence = confidence\n",
    "        e2_after_nu = e2_after\n",
    "        print('Found ' + str(prediction))\n",
    "        \n",
    "        window_size += 1\n",
    "        idx2 = idx1 + window_size\n",
    "        while prediction == nu_prediction and idx2 < len(words_after) and max_confidence >= nu_confidence - 1 :\n",
    "            e2_after = e2_after_nu\n",
    "            \n",
    "            e2_after_nu = words_after[:idx1] + ['<e2>'] + words_after[idx1:idx2] + ['</e2>'] + words_after[idx2:]\n",
    "            nu_line = [['Other', sentence[:i2] + ' ' + ' '.join(e2_after_nu)]]\n",
    "            nu_prediction, nu_confidence = predict_line(nu_line)\n",
    "            print(nu_prediction)\n",
    "            if nu_confidence > max_confidence :\n",
    "                max_confidence = nu_confidence\n",
    "            \n",
    "            window_size += 1\n",
    "            idx2 = idx1 + window_size\n",
    "            \n",
    "        preds.append([str(prediction), sentence[:i2] + ' ' + ' '.join(e2_after)])\n",
    "        idx1 += window_size - 2\n",
    "        window_size = window_size_start\n",
    "    else :\n",
    "        idx1 += 1\n",
    "# lines.append(['HAS_FUNCTION', '<e1> Grab samplers </e1> are buckets or segments that <e2> drive into the sediment layer and enclose and retain a layer </e2> .'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6',\n",
       "  'Geer moraines or <e1> washboard moraines  </e1> are series <e2> of small </e2> and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['3',\n",
       "  'Geer moraines or <e1> washboard moraines  </e1> are series of small and <e2> roughly parallel ridges </e2> of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['4',\n",
       "  'Geer moraines or <e1> washboard moraines  </e1> are series of small and roughly parallel ridges <e2> of till </e2> that are ordinarily associated with lakes or former lakes .']]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "examples = processor._create_examples(lines, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = convert_examples_to_features(\n",
    "    examples, conf['max_length'], tokenizer, add_sep_token=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long, device=device)\n",
    "all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long, device=device)\n",
    "all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long, device=device)\n",
    "all_e1_mask = torch.tensor([f.e1_mask for f in features], dtype=torch.long, device=device)  # add e1 mask\n",
    "all_e2_mask = torch.tensor([f.e2_mask for f in features], dtype=torch.long, device=device)  # add e2 mask\n",
    "\n",
    "all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(len(all_input_ids))\n",
    "with torch.no_grad():\n",
    "    outputs = model(all_input_ids, all_attention_mask, all_token_type_ids, None, all_e1_mask, all_e2_mask)\n",
    "    logits = outputs[0].detach().cpu().numpy()\n",
    "    probs = softmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.540789  , -1.9406198 , -1.4902645 , -1.8921092 , -1.5461885 ,\n",
       "        -2.1296341 , -1.4779458 ],\n",
       "       [10.175579  , -1.5989631 , -1.5731035 , -1.9601575 , -1.3176928 ,\n",
       "        -2.2539062 , -1.5726503 ],\n",
       "       [10.309549  , -2.1937    , -1.429167  , -1.6343846 , -1.6824181 ,\n",
       "        -2.1121252 , -1.617209  ],\n",
       "       [10.440431  , -1.7740446 , -1.6110647 , -1.7429495 , -1.7683027 ,\n",
       "        -1.989427  , -1.9434831 ],\n",
       "       [ 8.120712  ,  0.82375026, -1.4609393 , -1.7021438 , -2.2573965 ,\n",
       "        -2.1428084 , -2.2404277 ],\n",
       "       [-1.7056692 ,  9.201068  , -1.2181455 , -1.8262587 , -1.939174  ,\n",
       "        -2.1097791 , -1.4957887 ],\n",
       "       [-2.1209626 ,  9.431411  , -1.0019859 , -1.8649789 , -1.5667375 ,\n",
       "        -2.036273  , -1.7351724 ],\n",
       "       [ 8.027953  ,  0.6024179 , -1.5878698 , -1.6910765 , -2.134036  ,\n",
       "        -1.9717289 , -2.0567887 ],\n",
       "       [ 0.6234943 ,  7.865587  , -1.4714093 , -2.1363072 , -1.6687295 ,\n",
       "        -2.0495079 , -1.5996628 ],\n",
       "       [ 9.492211  , -0.35233727, -1.4837633 , -1.826169  , -2.0235074 ,\n",
       "        -2.1009254 , -2.0889316 ],\n",
       "       [-0.45099077,  8.560318  , -1.3851697 , -1.9346833 , -2.2023904 ,\n",
       "        -2.126023  , -1.6771222 ],\n",
       "       [-1.8326133 ,  9.330568  , -1.4618012 , -1.4431965 , -1.936603  ,\n",
       "        -1.71005   , -1.6017535 ],\n",
       "       [ 4.3437066 ,  3.756411  , -1.7467121 , -1.2246193 , -2.5696845 ,\n",
       "        -1.7737416 , -2.4546778 ],\n",
       "       [-2.143733  ,  7.091795  , -0.4457279 , -1.9007039 ,  0.20762515,\n",
       "        -2.632453  , -1.8864698 ],\n",
       "       [ 7.4817348 , -0.23601343, -1.293939  , -1.8976786 , -0.69886285,\n",
       "        -2.17579   , -2.3437712 ],\n",
       "       [-1.329139  ,  2.4594436 , -0.95827955, -1.0856483 ,  4.3894367 ,\n",
       "        -2.4063494 , -2.6002874 ],\n",
       "       [-3.061491  ,  4.488627  ,  0.81399006,  1.7340086 , -0.44525856,\n",
       "        -2.235732  , -3.1321099 ],\n",
       "       [ 7.9166455 ,  0.77075416, -1.6845305 , -1.7213156 , -1.7673622 ,\n",
       "        -2.1815069 , -2.2379365 ],\n",
       "       [-1.2551357 ,  9.027868  , -1.3120568 , -1.9016321 , -1.8552483 ,\n",
       "        -2.159324  , -1.619859  ],\n",
       "       [-1.810634  ,  9.492728  , -1.4457339 , -1.7238146 , -1.7328066 ,\n",
       "        -1.9763343 , -1.691445  ],\n",
       "       [-1.1038632 ,  8.448908  , -0.9740709 , -2.081278  , -1.9858912 ,\n",
       "        -2.063022  , -1.8037204 ],\n",
       "       [-2.2314892 ,  0.8077253 ,  6.839607  , -2.2487962 ,  1.3724767 ,\n",
       "        -2.9208503 , -2.5433676 ],\n",
       "       [-2.9532104 ,  1.1427757 ,  8.6735    , -2.2735028 , -0.1844355 ,\n",
       "        -2.1127613 , -2.4496765 ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logits = outputs[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.540789  , -1.9406198 , -1.4902645 , -1.8921092 , -1.5461885 ,\n",
       "        -2.1296341 , -1.4779458 ],\n",
       "       [10.175579  , -1.5989631 , -1.5731035 , -1.9601575 , -1.3176928 ,\n",
       "        -2.2539062 , -1.5726503 ],\n",
       "       [10.309549  , -2.1937    , -1.429167  , -1.6343846 , -1.6824181 ,\n",
       "        -2.1121252 , -1.617209  ],\n",
       "       [10.440431  , -1.7740446 , -1.6110647 , -1.7429495 , -1.7683027 ,\n",
       "        -1.989427  , -1.9434831 ],\n",
       "       [ 8.120712  ,  0.82375026, -1.4609393 , -1.7021438 , -2.2573965 ,\n",
       "        -2.1428084 , -2.2404277 ],\n",
       "       [-1.7056692 ,  9.201068  , -1.2181455 , -1.8262587 , -1.939174  ,\n",
       "        -2.1097791 , -1.4957887 ],\n",
       "       [-2.1209626 ,  9.431411  , -1.0019859 , -1.8649789 , -1.5667375 ,\n",
       "        -2.036273  , -1.7351724 ],\n",
       "       [ 8.027953  ,  0.6024179 , -1.5878698 , -1.6910765 , -2.134036  ,\n",
       "        -1.9717289 , -2.0567887 ],\n",
       "       [ 0.6234943 ,  7.865587  , -1.4714093 , -2.1363072 , -1.6687295 ,\n",
       "        -2.0495079 , -1.5996628 ],\n",
       "       [ 9.492211  , -0.35233727, -1.4837633 , -1.826169  , -2.0235074 ,\n",
       "        -2.1009254 , -2.0889316 ],\n",
       "       [-0.45099077,  8.560318  , -1.3851697 , -1.9346833 , -2.2023904 ,\n",
       "        -2.126023  , -1.6771222 ],\n",
       "       [-1.8326133 ,  9.330568  , -1.4618012 , -1.4431965 , -1.936603  ,\n",
       "        -1.71005   , -1.6017535 ],\n",
       "       [ 4.3437066 ,  3.756411  , -1.7467121 , -1.2246193 , -2.5696845 ,\n",
       "        -1.7737416 , -2.4546778 ],\n",
       "       [-2.143733  ,  7.091795  , -0.4457279 , -1.9007039 ,  0.20762515,\n",
       "        -2.632453  , -1.8864698 ],\n",
       "       [ 7.4817348 , -0.23601343, -1.293939  , -1.8976786 , -0.69886285,\n",
       "        -2.17579   , -2.3437712 ],\n",
       "       [-1.329139  ,  2.4594436 , -0.95827955, -1.0856483 ,  4.3894367 ,\n",
       "        -2.4063494 , -2.6002874 ],\n",
       "       [-3.061491  ,  4.488627  ,  0.81399006,  1.7340086 , -0.44525856,\n",
       "        -2.235732  , -3.1321099 ],\n",
       "       [ 7.9166455 ,  0.77075416, -1.6845305 , -1.7213156 , -1.7673622 ,\n",
       "        -2.1815069 , -2.2379365 ],\n",
       "       [-1.2551357 ,  9.027868  , -1.3120568 , -1.9016321 , -1.8552483 ,\n",
       "        -2.159324  , -1.619859  ],\n",
       "       [-1.810634  ,  9.492728  , -1.4457339 , -1.7238146 , -1.7328066 ,\n",
       "        -1.9763343 , -1.691445  ],\n",
       "       [-1.1038632 ,  8.448908  , -0.9740709 , -2.081278  , -1.9858912 ,\n",
       "        -2.063022  , -1.8037204 ],\n",
       "       [-2.2314892 ,  0.8077253 ,  6.839607  , -2.2487962 ,  1.3724767 ,\n",
       "        -2.9208503 , -2.5433676 ],\n",
       "       [-2.9532104 ,  1.1427757 ,  8.6735    , -2.2735028 , -0.1844355 ,\n",
       "        -2.1127613 , -2.4496765 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logits[logits < 8] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(logits, columns=processor.relation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Other</th>\n",
       "      <th>HAS_CAUSE</th>\n",
       "      <th>HAS_LOCATION</th>\n",
       "      <th>HAS_FORM</th>\n",
       "      <th>COMPOSITION_MEDIUM</th>\n",
       "      <th>HAS_FUNCTION</th>\n",
       "      <th>HAS_SIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.540789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.175579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.309549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.440431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.120712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.201068</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.431411</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.027953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.492211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.560318</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.330568</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.027868</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.492728</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.448908</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.6735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Other  HAS_CAUSE  HAS_LOCATION  HAS_FORM  COMPOSITION_MEDIUM  \\\n",
       "0   10.540789   0.000000        0.0000       0.0                 0.0   \n",
       "1   10.175579   0.000000        0.0000       0.0                 0.0   \n",
       "2   10.309549   0.000000        0.0000       0.0                 0.0   \n",
       "3   10.440431   0.000000        0.0000       0.0                 0.0   \n",
       "4    8.120712   0.000000        0.0000       0.0                 0.0   \n",
       "5    0.000000   9.201068        0.0000       0.0                 0.0   \n",
       "6    0.000000   9.431411        0.0000       0.0                 0.0   \n",
       "7    8.027953   0.000000        0.0000       0.0                 0.0   \n",
       "8    0.000000   0.000000        0.0000       0.0                 0.0   \n",
       "9    9.492211   0.000000        0.0000       0.0                 0.0   \n",
       "10   0.000000   8.560318        0.0000       0.0                 0.0   \n",
       "11   0.000000   9.330568        0.0000       0.0                 0.0   \n",
       "12   0.000000   0.000000        0.0000       0.0                 0.0   \n",
       "13   0.000000   0.000000        0.0000       0.0                 0.0   \n",
       "14   0.000000   0.000000        0.0000       0.0                 0.0   \n",
       "15   0.000000   0.000000        0.0000       0.0                 0.0   \n",
       "16   0.000000   0.000000        0.0000       0.0                 0.0   \n",
       "17   0.000000   0.000000        0.0000       0.0                 0.0   \n",
       "18   0.000000   9.027868        0.0000       0.0                 0.0   \n",
       "19   0.000000   9.492728        0.0000       0.0                 0.0   \n",
       "20   0.000000   8.448908        0.0000       0.0                 0.0   \n",
       "21   0.000000   0.000000        0.0000       0.0                 0.0   \n",
       "22   0.000000   0.000000        8.6735       0.0                 0.0   \n",
       "\n",
       "    HAS_FUNCTION  HAS_SIZE  \n",
       "0            0.0       0.0  \n",
       "1            0.0       0.0  \n",
       "2            0.0       0.0  \n",
       "3            0.0       0.0  \n",
       "4            0.0       0.0  \n",
       "5            0.0       0.0  \n",
       "6            0.0       0.0  \n",
       "7            0.0       0.0  \n",
       "8            0.0       0.0  \n",
       "9            0.0       0.0  \n",
       "10           0.0       0.0  \n",
       "11           0.0       0.0  \n",
       "12           0.0       0.0  \n",
       "13           0.0       0.0  \n",
       "14           0.0       0.0  \n",
       "15           0.0       0.0  \n",
       "16           0.0       0.0  \n",
       "17           0.0       0.0  \n",
       "18           0.0       0.0  \n",
       "19           0.0       0.0  \n",
       "20           0.0       0.0  \n",
       "21           0.0       0.0  \n",
       "22           0.0       0.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <e1> Eskers </e1> <e2> are the </e2> chief landform created by subglacial meltwater and form by the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "1 <e1> Eskers </e1> are <e2> the chief </e2> landform created by subglacial meltwater and form by the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "2 <e1> Eskers </e1> are the <e2> chief landform </e2> created by subglacial meltwater and form by the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "3 <e1> Eskers </e1> are the chief <e2> landform created </e2> by subglacial meltwater and form by the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "4 <e1> Eskers </e1> are the chief landform <e2> created by </e2> subglacial meltwater and form by the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "5 <e1> Eskers </e1> are the chief landform created <e2> by subglacial </e2> meltwater and form by the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "6 <e1> Eskers </e1> are the chief landform created by <e2> subglacial meltwater </e2> and form by the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "7 <e1> Eskers </e1> are the chief landform created by subglacial <e2> meltwater and </e2> form by the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "8 <e1> Eskers </e1> are the chief landform created by subglacial meltwater <e2> and form </e2> by the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "9 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and <e2> form by </e2> the infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "10 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form <e2> by the </e2> infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "11 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by <e2> the infilling </e2> of subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "12 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the <e2> infilling of </e2> subglacial or englacial channels or by sedimentation in supraglacial channels .\n",
      "13 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling <e2> of subglacial </e2> or englacial channels or by sedimentation in supraglacial channels .\n",
      "14 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling of <e2> subglacial or </e2> englacial channels or by sedimentation in supraglacial channels .\n",
      "15 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling of subglacial <e2> or englacial </e2> channels or by sedimentation in supraglacial channels .\n",
      "16 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling of subglacial or <e2> englacial channels </e2> or by sedimentation in supraglacial channels .\n",
      "17 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling of subglacial or englacial <e2> channels or </e2> by sedimentation in supraglacial channels .\n",
      "18 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling of subglacial or englacial channels <e2> or by </e2> sedimentation in supraglacial channels .\n",
      "19 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling of subglacial or englacial channels or <e2> by sedimentation </e2> in supraglacial channels .\n",
      "20 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling of subglacial or englacial channels or by <e2> sedimentation in </e2> supraglacial channels .\n",
      "21 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling of subglacial or englacial channels or by sedimentation <e2> in supraglacial </e2> channels .\n",
      "22 <e1> Eskers </e1> are the chief landform created by subglacial meltwater and form by the infilling of subglacial or englacial channels or by sedimentation in <e2> supraglacial channels </e2> .\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(lines)):\n",
    "    print(l, lines[l][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_vals = np.max(logits, axis=1)\n",
    "arg_max = np.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Other',\n",
       " '<e1> Eskers </e1> are the chief landform created by subglacial meltwater and form <e2> by the </e2> infilling of subglacial or englacial channels or by sedimentation in supraglacial channels .']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Other',\n",
       " 'HAS_CAUSE',\n",
       " 'HAS_LOCATION',\n",
       " 'HAS_FORM',\n",
       " 'COMPOSITION_MEDIUM',\n",
       " 'HAS_FUNCTION',\n",
       " 'HAS_SIZE']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.relation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/full_data_new_EN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>category</th>\n",
       "      <th>hierarchical</th>\n",
       "      <th>non-hierarchical</th>\n",
       "      <th>non-hierarchical-definitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>79</td>\n",
       "      <td>Geer</td>\n",
       "      <td>A.4_Other</td>\n",
       "      <td>DEFINIENDUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>79</td>\n",
       "      <td>moraines</td>\n",
       "      <td>A.4_Other</td>\n",
       "      <td>DEFINIENDUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>79</td>\n",
       "      <td>or</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>79</td>\n",
       "      <td>washboard</td>\n",
       "      <td>A.4_Other</td>\n",
       "      <td>DEFINIENDUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>79</td>\n",
       "      <td>moraines</td>\n",
       "      <td>A.4_Other</td>\n",
       "      <td>DEFINIENDUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>79</td>\n",
       "      <td>are</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFINITOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>79</td>\n",
       "      <td>series</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>79</td>\n",
       "      <td>of</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>79</td>\n",
       "      <td>small</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_SIZE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>79</td>\n",
       "      <td>and</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>79</td>\n",
       "      <td>roughly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_FORM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>79</td>\n",
       "      <td>parallel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_FORM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>79</td>\n",
       "      <td>ridges</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>79</td>\n",
       "      <td>of</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>79</td>\n",
       "      <td>till</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>79</td>\n",
       "      <td>that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>79</td>\n",
       "      <td>are</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>79</td>\n",
       "      <td>ordinarily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>79</td>\n",
       "      <td>associated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>79</td>\n",
       "      <td>with</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>79</td>\n",
       "      <td>lakes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>79</td>\n",
       "      <td>or</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>79</td>\n",
       "      <td>former</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>79</td>\n",
       "      <td>lakes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>79</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence        Word   category hierarchical non-hierarchical  \\\n",
       "1703        79        Geer  A.4_Other  DEFINIENDUM              NaN   \n",
       "1704        79    moraines  A.4_Other  DEFINIENDUM              NaN   \n",
       "1705        79          or        NaN          NaN              NaN   \n",
       "1706        79   washboard  A.4_Other  DEFINIENDUM              NaN   \n",
       "1707        79    moraines  A.4_Other  DEFINIENDUM              NaN   \n",
       "1708        79         are        NaN    DEFINITOR              NaN   \n",
       "1709        79      series        NaN          NaN              NaN   \n",
       "1710        79          of        NaN          NaN              NaN   \n",
       "1711        79       small        NaN          NaN         HAS_SIZE   \n",
       "1712        79         and        NaN          NaN              NaN   \n",
       "1713        79     roughly        NaN          NaN         HAS_FORM   \n",
       "1714        79    parallel        NaN          NaN         HAS_FORM   \n",
       "1715        79      ridges        NaN        GENUS              NaN   \n",
       "1716        79          of        NaN        GENUS              NaN   \n",
       "1717        79        till        NaN        GENUS              NaN   \n",
       "1718        79        that        NaN          NaN              NaN   \n",
       "1719        79         are        NaN          NaN              NaN   \n",
       "1720        79  ordinarily        NaN          NaN              NaN   \n",
       "1721        79  associated        NaN          NaN        HAS_CAUSE   \n",
       "1722        79        with        NaN          NaN        HAS_CAUSE   \n",
       "1723        79       lakes        NaN          NaN        HAS_CAUSE   \n",
       "1724        79          or        NaN          NaN        HAS_CAUSE   \n",
       "1725        79      former        NaN          NaN        HAS_CAUSE   \n",
       "1726        79       lakes        NaN          NaN        HAS_CAUSE   \n",
       "1727        79           .        NaN          NaN              NaN   \n",
       "\n",
       "     non-hierarchical-definitor  \n",
       "1703                        NaN  \n",
       "1704                        NaN  \n",
       "1705                        NaN  \n",
       "1706                        NaN  \n",
       "1707                        NaN  \n",
       "1708                        NaN  \n",
       "1709                        NaN  \n",
       "1710                        NaN  \n",
       "1711                        NaN  \n",
       "1712                        NaN  \n",
       "1713                        NaN  \n",
       "1714                        NaN  \n",
       "1715                        NaN  \n",
       "1716                        NaN  \n",
       "1717                        NaN  \n",
       "1718                        NaN  \n",
       "1719                        NaN  \n",
       "1720                        NaN  \n",
       "1721                        NaN  \n",
       "1722                        NaN  \n",
       "1723                        NaN  \n",
       "1724                        NaN  \n",
       "1725                        NaN  \n",
       "1726                        NaN  \n",
       "1727                        NaN  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Sentence'] ==79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Other',\n",
       "  '<e2> Geer moraines </e2> or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer <e2> moraines or </e2> <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> <e2> are series </e2> of small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are <e2> series of </e2> small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series <e2> of small </e2> and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of <e2> small and </e2> roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small <e2> and roughly </e2> parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and <e2> roughly parallel </e2> ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly <e2> parallel ridges </e2> of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel <e2> ridges of </e2> till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges <e2> of till </e2> that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of <e2> till that </e2> are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till <e2> that are </e2> ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that <e2> are ordinarily </e2> associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are <e2> ordinarily associated </e2> with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily <e2> associated with </e2> lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated <e2> with lakes </e2> or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with <e2> lakes or </e2> former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes <e2> or former </e2> lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes or <e2> former lakes </e2> .']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.3230584 , -0.28777394,  0.3915504 ,  2.6353245 ,  4.0684237 ,\n",
       "        -2.2714093 , -2.2305045 ],\n",
       "       [-3.61521   , -0.5822604 , -0.27176338,  2.2229083 ,  4.8831253 ,\n",
       "        -1.4569333 , -2.4374123 ],\n",
       "       [-1.7090881 , -1.5794371 , -1.728625  ,  8.812912  , -1.9842335 ,\n",
       "        -1.9991543 ,  0.09666806],\n",
       "       [-1.2743081 , -2.2612534 , -2.9260657 ,  3.9110909 , -1.0057275 ,\n",
       "        -2.1319952 ,  5.9472904 ],\n",
       "       [-0.54082996, -1.9248059 , -1.7650276 , -1.7264402 , -0.8863953 ,\n",
       "        -1.4189417 ,  8.554747  ],\n",
       "       [-0.60751706, -1.9159092 , -1.8468326 , -1.3841116 , -1.2140503 ,\n",
       "        -1.4515196 ,  8.654597  ],\n",
       "       [-1.0642627 , -2.164248  , -2.4575984 ,  1.93889   , -2.2918904 ,\n",
       "        -1.38612   ,  7.6464434 ],\n",
       "       [-1.6847495 , -1.7833356 , -1.3581494 ,  9.161529  , -2.1036088 ,\n",
       "        -1.3656468 , -0.9450502 ],\n",
       "       [-1.6853762 , -1.6389939 , -1.13269   ,  9.09769   , -2.0025904 ,\n",
       "        -1.4591932 , -1.2642449 ],\n",
       "       [-1.8404146 , -1.7514817 , -1.6753707 ,  9.04278   , -1.0255224 ,\n",
       "        -1.8486793 , -1.0904444 ],\n",
       "       [-1.5635793 , -1.586362  , -1.6831613 , -1.628636  ,  8.372835  ,\n",
       "        -2.0301938 , -1.500188  ],\n",
       "       [-2.0236273 , -1.5585464 , -1.2902132 , -0.73045397,  8.006242  ,\n",
       "        -2.0117538 , -1.990935  ],\n",
       "       [-2.7733827 , -2.2171957 ,  2.8644423 , -1.5250394 ,  5.095961  ,\n",
       "        -0.799772  , -2.0302632 ],\n",
       "       [-1.5974383 , -1.6687661 , -2.4607022 ,  3.6992786 , -1.5447176 ,\n",
       "        -1.7968702 ,  5.4789658 ],\n",
       "       [-2.5551467 , -1.3855448 ,  3.4117494 ,  5.5199943 , -1.7319908 ,\n",
       "        -1.403017  , -2.0599663 ],\n",
       "       [-2.2845495 , -0.4455069 ,  7.614552  , -1.9657071 , -0.0957377 ,\n",
       "         0.02467517, -3.0197854 ],\n",
       "       [-2.4102595 , -0.8277441 ,  2.647827  , -2.891879  ,  1.126127  ,\n",
       "         4.6769176 , -2.9316008 ],\n",
       "       [-2.7246892 , -0.00973041,  1.7271059 , -3.0983963 ,  3.023421  ,\n",
       "         3.2553415 , -3.0925283 ],\n",
       "       [-2.7484603 ,  2.4173841 , -1.0053535 , -2.6269832 ,  3.9299717 ,\n",
       "         1.7272971 , -2.9855077 ],\n",
       "       [-2.3696432 , -1.3152204 ,  1.2258085 , -2.8556025 ,  2.2879102 ,\n",
       "         4.742125  , -2.4378397 ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logits = outputs[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.3230584 , -0.28777394,  0.3915504 ,  2.6353245 ,  4.0684237 ,\n",
       "        -2.2714093 , -2.2305045 ],\n",
       "       [-3.61521   , -0.5822604 , -0.27176338,  2.2229083 ,  4.8831253 ,\n",
       "        -1.4569333 , -2.4374123 ],\n",
       "       [-1.7090881 , -1.5794371 , -1.728625  ,  8.812912  , -1.9842335 ,\n",
       "        -1.9991543 ,  0.09666806],\n",
       "       [-1.2743081 , -2.2612534 , -2.9260657 ,  3.9110909 , -1.0057275 ,\n",
       "        -2.1319952 ,  5.9472904 ],\n",
       "       [-0.54082996, -1.9248059 , -1.7650276 , -1.7264402 , -0.8863953 ,\n",
       "        -1.4189417 ,  8.554747  ],\n",
       "       [-0.60751706, -1.9159092 , -1.8468326 , -1.3841116 , -1.2140503 ,\n",
       "        -1.4515196 ,  8.654597  ],\n",
       "       [-1.0642627 , -2.164248  , -2.4575984 ,  1.93889   , -2.2918904 ,\n",
       "        -1.38612   ,  7.6464434 ],\n",
       "       [-1.6847495 , -1.7833356 , -1.3581494 ,  9.161529  , -2.1036088 ,\n",
       "        -1.3656468 , -0.9450502 ],\n",
       "       [-1.6853762 , -1.6389939 , -1.13269   ,  9.09769   , -2.0025904 ,\n",
       "        -1.4591932 , -1.2642449 ],\n",
       "       [-1.8404146 , -1.7514817 , -1.6753707 ,  9.04278   , -1.0255224 ,\n",
       "        -1.8486793 , -1.0904444 ],\n",
       "       [-1.5635793 , -1.586362  , -1.6831613 , -1.628636  ,  8.372835  ,\n",
       "        -2.0301938 , -1.500188  ],\n",
       "       [-2.0236273 , -1.5585464 , -1.2902132 , -0.73045397,  8.006242  ,\n",
       "        -2.0117538 , -1.990935  ],\n",
       "       [-2.7733827 , -2.2171957 ,  2.8644423 , -1.5250394 ,  5.095961  ,\n",
       "        -0.799772  , -2.0302632 ],\n",
       "       [-1.5974383 , -1.6687661 , -2.4607022 ,  3.6992786 , -1.5447176 ,\n",
       "        -1.7968702 ,  5.4789658 ],\n",
       "       [-2.5551467 , -1.3855448 ,  3.4117494 ,  5.5199943 , -1.7319908 ,\n",
       "        -1.403017  , -2.0599663 ],\n",
       "       [-2.2845495 , -0.4455069 ,  7.614552  , -1.9657071 , -0.0957377 ,\n",
       "         0.02467517, -3.0197854 ],\n",
       "       [-2.4102595 , -0.8277441 ,  2.647827  , -2.891879  ,  1.126127  ,\n",
       "         4.6769176 , -2.9316008 ],\n",
       "       [-2.7246892 , -0.00973041,  1.7271059 , -3.0983963 ,  3.023421  ,\n",
       "         3.2553415 , -3.0925283 ],\n",
       "       [-2.7484603 ,  2.4173841 , -1.0053535 , -2.6269832 ,  3.9299717 ,\n",
       "         1.7272971 , -2.9855077 ],\n",
       "       [-2.3696432 , -1.3152204 ,  1.2258085 , -2.8556025 ,  2.2879102 ,\n",
       "         4.742125  , -2.4378397 ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logits[logits < 8] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(logits, columns=processor.relation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Other</th>\n",
       "      <th>HAS_CAUSE</th>\n",
       "      <th>HAS_LOCATION</th>\n",
       "      <th>HAS_FORM</th>\n",
       "      <th>COMPOSITION_MEDIUM</th>\n",
       "      <th>HAS_FUNCTION</th>\n",
       "      <th>HAS_SIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.812912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.554747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.654597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.161529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.097690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.042780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.372835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.006242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Other  HAS_CAUSE  HAS_LOCATION  HAS_FORM  COMPOSITION_MEDIUM  \\\n",
       "0     0.0        0.0           0.0  0.000000            0.000000   \n",
       "1     0.0        0.0           0.0  0.000000            0.000000   \n",
       "2     0.0        0.0           0.0  8.812912            0.000000   \n",
       "3     0.0        0.0           0.0  0.000000            0.000000   \n",
       "4     0.0        0.0           0.0  0.000000            0.000000   \n",
       "5     0.0        0.0           0.0  0.000000            0.000000   \n",
       "6     0.0        0.0           0.0  0.000000            0.000000   \n",
       "7     0.0        0.0           0.0  9.161529            0.000000   \n",
       "8     0.0        0.0           0.0  9.097690            0.000000   \n",
       "9     0.0        0.0           0.0  9.042780            0.000000   \n",
       "10    0.0        0.0           0.0  0.000000            8.372835   \n",
       "11    0.0        0.0           0.0  0.000000            8.006242   \n",
       "12    0.0        0.0           0.0  0.000000            0.000000   \n",
       "13    0.0        0.0           0.0  0.000000            0.000000   \n",
       "14    0.0        0.0           0.0  0.000000            0.000000   \n",
       "15    0.0        0.0           0.0  0.000000            0.000000   \n",
       "16    0.0        0.0           0.0  0.000000            0.000000   \n",
       "17    0.0        0.0           0.0  0.000000            0.000000   \n",
       "18    0.0        0.0           0.0  0.000000            0.000000   \n",
       "19    0.0        0.0           0.0  0.000000            0.000000   \n",
       "\n",
       "    HAS_FUNCTION  HAS_SIZE  \n",
       "0            0.0  0.000000  \n",
       "1            0.0  0.000000  \n",
       "2            0.0  0.000000  \n",
       "3            0.0  0.000000  \n",
       "4            0.0  8.554747  \n",
       "5            0.0  8.654597  \n",
       "6            0.0  0.000000  \n",
       "7            0.0  0.000000  \n",
       "8            0.0  0.000000  \n",
       "9            0.0  0.000000  \n",
       "10           0.0  0.000000  \n",
       "11           0.0  0.000000  \n",
       "12           0.0  0.000000  \n",
       "13           0.0  0.000000  \n",
       "14           0.0  0.000000  \n",
       "15           0.0  0.000000  \n",
       "16           0.0  0.000000  \n",
       "17           0.0  0.000000  \n",
       "18           0.0  0.000000  \n",
       "19           0.0  0.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <e2> Geer moraines </e2> or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .\n",
      "1 Geer <e2> moraines or </e2> <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .\n",
      "2 Geer moraines or <e1> washboard moraines </e1> <e2> are series </e2> of small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .\n",
      "3 Geer moraines or <e1> washboard moraines </e1> are <e2> series of </e2> small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .\n",
      "4 Geer moraines or <e1> washboard moraines </e1> are series <e2> of small </e2> and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .\n",
      "5 Geer moraines or <e1> washboard moraines </e1> are series of <e2> small and </e2> roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .\n",
      "6 Geer moraines or <e1> washboard moraines </e1> are series of small <e2> and roughly </e2> parallel ridges of till that are ordinarily associated with lakes or former lakes .\n",
      "7 Geer moraines or <e1> washboard moraines </e1> are series of small and <e2> roughly parallel </e2> ridges of till that are ordinarily associated with lakes or former lakes .\n",
      "8 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly <e2> parallel ridges </e2> of till that are ordinarily associated with lakes or former lakes .\n",
      "9 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel <e2> ridges of </e2> till that are ordinarily associated with lakes or former lakes .\n",
      "10 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges <e2> of till </e2> that are ordinarily associated with lakes or former lakes .\n",
      "11 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of <e2> till that </e2> are ordinarily associated with lakes or former lakes .\n",
      "12 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till <e2> that are </e2> ordinarily associated with lakes or former lakes .\n",
      "13 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that <e2> are ordinarily </e2> associated with lakes or former lakes .\n",
      "14 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are <e2> ordinarily associated </e2> with lakes or former lakes .\n",
      "15 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily <e2> associated with </e2> lakes or former lakes .\n",
      "16 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated <e2> with lakes </e2> or former lakes .\n",
      "17 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with <e2> lakes or </e2> former lakes .\n",
      "18 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes <e2> or former </e2> lakes .\n",
      "19 Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes or <e2> former lakes </e2> .\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(lines)):\n",
    "    print(l, lines[l][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_vals = np.max(logits, axis=1)\n",
    "arg_max = np.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Other',\n",
       " 'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are <e2> ordinarily associated with </e2> lakes or former lakes .']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Other',\n",
       " 'HAS_CAUSE',\n",
       " 'HAS_LOCATION',\n",
       " 'HAS_FORM',\n",
       " 'COMPOSITION_MEDIUM',\n",
       " 'HAS_FUNCTION',\n",
       " 'HAS_SIZE']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.relation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/full_data_new_EN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>category</th>\n",
       "      <th>hierarchical</th>\n",
       "      <th>non-hierarchical</th>\n",
       "      <th>non-hierarchical-definitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>79</td>\n",
       "      <td>Geer</td>\n",
       "      <td>A.4_Other</td>\n",
       "      <td>DEFINIENDUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>79</td>\n",
       "      <td>moraines</td>\n",
       "      <td>A.4_Other</td>\n",
       "      <td>DEFINIENDUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>79</td>\n",
       "      <td>or</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>79</td>\n",
       "      <td>washboard</td>\n",
       "      <td>A.4_Other</td>\n",
       "      <td>DEFINIENDUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>79</td>\n",
       "      <td>moraines</td>\n",
       "      <td>A.4_Other</td>\n",
       "      <td>DEFINIENDUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>79</td>\n",
       "      <td>are</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEFINITOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>79</td>\n",
       "      <td>series</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>79</td>\n",
       "      <td>of</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>79</td>\n",
       "      <td>small</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_SIZE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>79</td>\n",
       "      <td>and</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>79</td>\n",
       "      <td>roughly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_FORM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>79</td>\n",
       "      <td>parallel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_FORM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>79</td>\n",
       "      <td>ridges</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>79</td>\n",
       "      <td>of</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>79</td>\n",
       "      <td>till</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>79</td>\n",
       "      <td>that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>79</td>\n",
       "      <td>are</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>79</td>\n",
       "      <td>ordinarily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>79</td>\n",
       "      <td>associated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>79</td>\n",
       "      <td>with</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>79</td>\n",
       "      <td>lakes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>79</td>\n",
       "      <td>or</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>79</td>\n",
       "      <td>former</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>79</td>\n",
       "      <td>lakes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAS_CAUSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>79</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence        Word   category hierarchical non-hierarchical  \\\n",
       "1703        79        Geer  A.4_Other  DEFINIENDUM              NaN   \n",
       "1704        79    moraines  A.4_Other  DEFINIENDUM              NaN   \n",
       "1705        79          or        NaN          NaN              NaN   \n",
       "1706        79   washboard  A.4_Other  DEFINIENDUM              NaN   \n",
       "1707        79    moraines  A.4_Other  DEFINIENDUM              NaN   \n",
       "1708        79         are        NaN    DEFINITOR              NaN   \n",
       "1709        79      series        NaN          NaN              NaN   \n",
       "1710        79          of        NaN          NaN              NaN   \n",
       "1711        79       small        NaN          NaN         HAS_SIZE   \n",
       "1712        79         and        NaN          NaN              NaN   \n",
       "1713        79     roughly        NaN          NaN         HAS_FORM   \n",
       "1714        79    parallel        NaN          NaN         HAS_FORM   \n",
       "1715        79      ridges        NaN        GENUS              NaN   \n",
       "1716        79          of        NaN        GENUS              NaN   \n",
       "1717        79        till        NaN        GENUS              NaN   \n",
       "1718        79        that        NaN          NaN              NaN   \n",
       "1719        79         are        NaN          NaN              NaN   \n",
       "1720        79  ordinarily        NaN          NaN              NaN   \n",
       "1721        79  associated        NaN          NaN        HAS_CAUSE   \n",
       "1722        79        with        NaN          NaN        HAS_CAUSE   \n",
       "1723        79       lakes        NaN          NaN        HAS_CAUSE   \n",
       "1724        79          or        NaN          NaN        HAS_CAUSE   \n",
       "1725        79      former        NaN          NaN        HAS_CAUSE   \n",
       "1726        79       lakes        NaN          NaN        HAS_CAUSE   \n",
       "1727        79           .        NaN          NaN              NaN   \n",
       "\n",
       "     non-hierarchical-definitor  \n",
       "1703                        NaN  \n",
       "1704                        NaN  \n",
       "1705                        NaN  \n",
       "1706                        NaN  \n",
       "1707                        NaN  \n",
       "1708                        NaN  \n",
       "1709                        NaN  \n",
       "1710                        NaN  \n",
       "1711                        NaN  \n",
       "1712                        NaN  \n",
       "1713                        NaN  \n",
       "1714                        NaN  \n",
       "1715                        NaN  \n",
       "1716                        NaN  \n",
       "1717                        NaN  \n",
       "1718                        NaN  \n",
       "1719                        NaN  \n",
       "1720                        NaN  \n",
       "1721                        NaN  \n",
       "1722                        NaN  \n",
       "1723                        NaN  \n",
       "1724                        NaN  \n",
       "1725                        NaN  \n",
       "1726                        NaN  \n",
       "1727                        NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Sentence'] ==79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Other',\n",
       "  '<e2> Geer moraines or </e2> <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of <e2> small and roughly </e2> parallel ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small <e2> and roughly parallel </e2> ridges of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and <e2> roughly parallel ridges </e2> of till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly <e2> parallel ridges of </e2> till that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel <e2> ridges of till </e2> that are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges <e2> of till that </e2> are ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of <e2> till that are </e2> ordinarily associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till <e2> that are ordinarily </e2> associated with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that <e2> are ordinarily associated </e2> with lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are <e2> ordinarily associated with </e2> lakes or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily <e2> associated with lakes </e2> or former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated <e2> with lakes or </e2> former lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with <e2> lakes or former </e2> lakes .'],\n",
       " ['Other',\n",
       "  'Geer moraines or <e1> washboard moraines </e1> are series of small and roughly parallel ridges of till that are ordinarily associated with lakes <e2> or former lakes </e2> .'],\n",
       " ['HAS_FUNCTION',\n",
       "  '<e1> Grab samplers </e1> are buckets or segments that <e2> drive into the sediment layer and enclose and retain a layer </e2> .']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
